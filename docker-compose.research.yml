version: '3'

services:
  # Deep Researcher service with LangGraph
  deep-researcher:
    build:
      context: ./ollama-deep-researcher-ts
      dockerfile: ./docker/Dockerfile
    ports:
      - "2024:2024"
    environment:
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - LLM_BASE_URL=http://host.docker.internal:11434
      - MODEL_NAME=llama3
      - RESEARCH_ITERATIONS=3
      - NODE_ENV=production
    volumes:
      - ./ollama-deep-researcher-ts:/app
    networks:
      - research-network
    extra_hosts:
      - host.docker.internal:host-gateway

  # OpenManus service for agent-based analysis
  openmanus:
    build:
      context: ./research/OpenManus
      dockerfile: Dockerfile
    ports:
      - "3006:3006"
    environment:
      - OLLAMA_URL=http://host.docker.internal:11434
    volumes:
      - ./research/OpenManus:/app
    networks:
      - research-network
    depends_on:
      - deep-researcher
    extra_hosts:
      - host.docker.internal:host-gateway

  # OpenWeb-UI for user interface
  openweb-ui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_BASE_URLS=http://host.docker.internal:11434
      - ENV=dev
      - WEBUI_AUTH=False
      - RESEARCH_API_URL=http://deep-researcher:2024
      - OPENMANUS_API_URL=http://openmanus:3006
    volumes:
      - ./data:/app/backend/data
    networks:
      - research-network
    depends_on:
      - deep-researcher
      - openmanus
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

networks:
  research-network:
    driver: bridge 