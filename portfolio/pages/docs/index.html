<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Ollama Ecosystem - Comprehensive Documentation">
    <title>Documentation | Ollama Ecosystem</title>
    
    <!-- Stylesheets -->
    <link rel="stylesheet" href="../../assets/css/styles.css">
    
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Poppins:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Syntax Highlighting - Prism.js -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-tomorrow.min.css" />
</head>
<body>
    <!-- Header -->
    <header>
        <div class="header-container">
            <div class="logo">
                <img src="../../assets/images/llm-icon.svg" alt="Ollama Ecosystem Logo">
                <div>
                    <h1>Ollama Ecosystem</h1>
                    <span class="tagline">Sovereign AI Solutions</span>
                </div>
            </div>
            <div class="mobile-menu-toggle">
                <span></span>
                <span></span>
                <span></span>
            </div>
            <nav class="navigation">
                <a href="../../index.html">Home</a>
                <a href="../reports/index.html">Reports</a>
                <a href="../docs/index.html" class="active">Documentation</a>
                <a href="../downloads/index.html">Downloads</a>
                <a href="../tutorials/index.html">Tutorials</a>
                <a href="../contact/index.html">Contact</a>
                <a href="../careers/index.html">Careers</a>
                <a href="../best-practices/index.html">Best Practices</a>
            </nav>
        </div>
    </header>

    <main>
        <!-- Documentation Header -->
        <section class="hero hero-small">
            <div class="hero-background"></div>
            <div class="container">
                <div class="hero-content text-center">
                    <h2 class="hero-title">Technical <span class="text-gradient">Documentation</span></h2>
                    <p class="hero-description">
                        Comprehensive guides and reference materials for the Ollama Ecosystem
                    </p>
                </div>
            </div>
        </section>
        
        <!-- Documentation Content -->
        <section class="documentation">
            <div class="container">
                <div class="docs-layout">
                    <!-- Sidebar Navigation -->
                    <div class="docs-sidebar">
                        <div class="docs-nav">
                            <div class="docs-nav-section">
                                <h3>Getting Started</h3>
                                <a href="#introduction" class="active">Introduction</a>
                                <a href="#installation">Installation Guide</a>
                                <a href="#quick-start">Quick Start</a>
                                <a href="#concepts">Core Concepts</a>
                            </div>
                            <div class="docs-nav-section">
                                <h3>API Reference</h3>
                                <a href="#rest-api">REST API</a>
                                <a href="#cli-reference">CLI Reference</a>
                                <a href="#websocket-api">WebSocket API</a>
                                <a href="#libraries">Client Libraries</a>
                            </div>
                            <div class="docs-nav-section">
                                <h3>Features</h3>
                                <a href="#models">Model Management</a>
                                <a href="#content-agent">Content Creator Agent</a>
                                <a href="#contexts">Context Management</a>
                                <a href="#integrations">Integrations</a>
                            </div>
                            <div class="docs-nav-section">
                                <h3>Advanced</h3>
                                <a href="#performance">Performance Tuning</a>
                                <a href="#security">Security & Privacy</a>
                                <a href="#extensions">Building Extensions</a>
                                <a href="#deployment">Deployment Patterns</a>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Documentation Content -->
                    <div class="docs-content">
                        <section id="introduction" class="docs-section">
                            <h2>Introduction to Ollama Ecosystem</h2>
                            <p>
                                Ollama Ecosystem is a comprehensive platform for running local AI models with a focus on privacy, performance, and ease of use. This documentation provides everything you need to get started, understand the architecture, and build applications with our technology.
                            </p>
                            
                            <div class="info-box">
                                <h4><i class="fas fa-info-circle"></i> What is Ollama?</h4>
                                <p>
                                    Ollama allows you to run large language models locally on your machine, giving you the power of advanced AI without sending your data to external services. The ecosystem provides tools, extensions, and applications that build on this foundation.
                                </p>
                            </div>
                            
                            <h3>Key Features</h3>
                            <ul class="feature-list">
                                <li><i class="fas fa-check"></i> <strong>Local Execution:</strong> Run models directly on your machine without external dependencies</li>
                                <li><i class="fas fa-check"></i> <strong>Privacy First:</strong> Your data never leaves your device</li>
                                <li><i class="fas fa-check"></i> <strong>Powerful API:</strong> Simple REST API for application integration</li>
                                <li><i class="fas fa-check"></i> <strong>Multiple Models:</strong> Support for various language models optimized for different tasks</li>
                                <li><i class="fas fa-check"></i> <strong>Content Creator Agent:</strong> Automated content generation and management</li>
                                <li><i class="fas fa-check"></i> <strong>Context Management:</strong> Advanced context handling for improved responses</li>
                                <li><i class="fas fa-check"></i> <strong>Extensible:</strong> Build and share extensions to enhance functionality</li>
                            </ul>
                        </section>
                        
                        <section id="installation" class="docs-section">
                            <h2>Installation Guide</h2>
                            <p>
                                Ollama Ecosystem can be installed on various platforms. Follow the instructions below for your operating system.
                            </p>
                            
                            <div class="tab-container">
                                <div class="tabs">
                                    <button class="tab-btn active" data-target="macos-install">macOS</button>
                                    <button class="tab-btn" data-target="windows-install">Windows</button>
                                    <button class="tab-btn" data-target="linux-install">Linux</button>
                                    <button class="tab-btn" data-target="docker-install">Docker</button>
                                </div>
                                
                                <div class="tab-content">
                                    <div id="macos-install" class="tab-pane active">
                                        <h3>Installing on macOS</h3>
                                        <p>Installation on macOS is straightforward using our installer package:</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-bash">curl -fsSL https://ollama.com/install.sh | sh</code></pre>
                                        </div>
                                        
                                        <p>Alternatively, you can use Homebrew:</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-bash">brew install ollama</code></pre>
                                        </div>
                                        
                                        <p>After installation, start the Ollama service:</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-bash">ollama serve</code></pre>
                                        </div>
                                    </div>
                                    
                                    <div id="windows-install" class="tab-pane">
                                        <h3>Installing on Windows</h3>
                                        <p>Download and run the Windows installer from our official site:</p>
                                        
                                        <a href="../downloads/index.html" class="btn">Download Windows Installer</a>
                                        
                                        <p>Or use the command line with PowerShell (Run as Administrator):</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-powershell">Invoke-WebRequest -Uri "https://ollama.com/download/ollama-windows.exe" -OutFile "ollama-setup.exe"
./ollama-setup.exe</code></pre>
                                        </div>
                                    </div>
                                    
                                    <div id="linux-install" class="tab-pane">
                                        <h3>Installing on Linux</h3>
                                        <p>For Debian-based distributions (Ubuntu, Debian, etc.):</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-bash">curl -fsSL https://ollama.com/install.sh | sh</code></pre>
                                        </div>
                                        
                                        <p>For Arch Linux:</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-bash">yay -S ollama</code></pre>
                                        </div>
                                        
                                        <p>Start the service:</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-bash">ollama serve</code></pre>
                                        </div>
                                    </div>
                                    
                                    <div id="docker-install" class="tab-pane">
                                        <h3>Using Docker</h3>
                                        <p>Pull and run our official Docker image:</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-bash">docker pull ollama/ollama
docker run -d -p 11434:11434 ollama/ollama</code></pre>
                                        </div>
                                        
                                        <p>For persistent storage of models:</p>
                                        
                                        <div class="code-block">
                                            <pre><code class="language-bash">docker run -d -p 11434:11434 \
  -v ollama:/root/.ollama \
  ollama/ollama</code></pre>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </section>
                        
                        <section id="quick-start" class="docs-section">
                            <h2>Quick Start Guide</h2>
                            <p>
                                Get up and running with Ollama Ecosystem in minutes by following these steps:
                            </p>
                            
                            <div class="step-by-step">
                                <div class="step">
                                    <div class="step-number">1</div>
                                    <div class="step-content">
                                        <h3>Install Ollama</h3>
                                        <p>Follow the installation instructions for your platform from the section above.</p>
                                    </div>
                                </div>
                                
                                <div class="step">
                                    <div class="step-number">2</div>
                                    <div class="step-content">
                                        <h3>Download a Model</h3>
                                        <p>Pull a language model to use with Ollama:</p>
                                        <div class="code-block">
                                            <pre><code class="language-bash">ollama pull llama2</code></pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="step">
                                    <div class="step-number">3</div>
                                    <div class="step-content">
                                        <h3>Run Your First Query</h3>
                                        <p>Interact with the model using a simple query:</p>
                                        <div class="code-block">
                                            <pre><code class="language-bash">ollama run llama2 "Explain the benefits of local AI models in simple terms"</code></pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="step">
                                    <div class="step-number">4</div>
                                    <div class="step-content">
                                        <h3>Try the API</h3>
                                        <p>Send a request to the API endpoint:</p>
                                        <div class="code-block">
                                            <pre><code class="language-bash">curl -X POST http://localhost:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "What are the advantages of running AI locally?",
  "stream": false
}'</code></pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="step">
                                    <div class="step-number">5</div>
                                    <div class="step-content">
                                        <h3>Explore the Ecosystem</h3>
                                        <p>Install additional tools and extensions to enhance your experience:</p>
                                        <div class="code-block">
                                            <pre><code class="language-bash">ollama-content-agent install
ollama-context-manager install</code></pre>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </section>
                        
                        <section id="rest-api" class="docs-section">
                            <h2>REST API Reference</h2>
                            <p>
                                The Ollama REST API provides a simple interface for interacting with language models. Here are the main endpoints:
                            </p>
                            
                            <div class="api-endpoint glass-card">
                                <div class="endpoint-method">POST</div>
                                <div class="endpoint-path">/api/generate</div>
                                <div class="endpoint-description">
                                    <p>Generate a completion for the given prompt</p>
                                    
                                    <h4>Request Parameters</h4>
                                    <div class="code-block">
                                        <pre><code class="language-json">{
  "model": "llama2",   // required: the model name
  "prompt": "Hello",   // required: the prompt to generate from
  "stream": true,      // optional: stream the response
  "options": {         // optional: model parameters
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 40,
    "max_tokens": 500
  }
}</code></pre>
                                    </div>
                                    
                                    <h4>Response</h4>
                                    <div class="code-block">
                                        <pre><code class="language-json">{
  "model": "llama2",
  "created_at": "2023-11-04T12:43:16.003Z",
  "response": "Hello! How can I assist you today?",
  "done": true,
  "context": [1, 2, 3, ...],  // context for further generation
  "total_duration": 375000000,
  "load_duration": 150000000,
  "prompt_eval_duration": 75000000,
  "eval_duration": 150000000
}</code></pre>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="api-endpoint glass-card">
                                <div class="endpoint-method">POST</div>
                                <div class="endpoint-path">/api/chat</div>
                                <div class="endpoint-description">
                                    <p>Generate a chat completion with message history</p>
                                    
                                    <h4>Request Parameters</h4>
                                    <div class="code-block">
                                        <pre><code class="language-json">{
  "model": "llama2",
  "messages": [
    {
      "role": "user",
      "content": "Hello, how are you?"
    },
    {
      "role": "assistant",
      "content": "I'm doing well, thank you! How can I help you today?"
    },
    {
      "role": "user",
      "content": "Explain the benefits of local AI models."
    }
  ],
  "stream": true,
  "options": {
    "temperature": 0.7
  }
}</code></pre>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="api-endpoint glass-card">
                                <div class="endpoint-method">POST</div>
                                <div class="endpoint-path">/api/embeddings</div>
                                <div class="endpoint-description">
                                    <p>Generate embeddings for the given text</p>
                                    
                                    <h4>Request Parameters</h4>
                                    <div class="code-block">
                                        <pre><code class="language-json">{
  "model": "llama2",
  "prompt": "The quick brown fox jumps over the lazy dog"
}</code></pre>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="api-endpoint glass-card">
                                <div class="endpoint-method">GET</div>
                                <div class="endpoint-path">/api/models</div>
                                <div class="endpoint-description">
                                    <p>List all available models</p>
                                </div>
                            </div>
                            
                            <div class="api-endpoint glass-card">
                                <div class="endpoint-method">POST</div>
                                <div class="endpoint-path">/api/pull</div>
                                <div class="endpoint-description">
                                    <p>Download a model</p>
                                    
                                    <h4>Request Parameters</h4>
                                    <div class="code-block">
                                        <pre><code class="language-json">{
  "name": "llama2"
}</code></pre>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="view-all-button">
                                <a href="../docs/api-reference.html" class="btn">View Complete API Reference</a>
                            </div>
                        </section>
                        
                        <section id="models" class="docs-section">
                            <h2>Model Management</h2>
                            <p>
                                Ollama Ecosystem supports a wide range of language models optimized for different tasks and hardware configurations.
                            </p>
                            
                            <h3>Available Models</h3>
                            <div class="table-container">
                                <table class="models-table">
                                    <thead>
                                        <tr>
                                            <th>Model</th>
                                            <th>Size</th>
                                            <th>Optimized For</th>
                                            <th>Min Hardware</th>
                                            <th>Download</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>Llama 2</td>
                                            <td>7B, 13B, 70B</td>
                                            <td>General purpose</td>
                                            <td>8GB RAM</td>
                                            <td><code>ollama pull llama2</code></td>
                                        </tr>
                                        <tr>
                                            <td>Mistral</td>
                                            <td>7B</td>
                                            <td>High efficiency</td>
                                            <td>8GB RAM</td>
                                            <td><code>ollama pull mistral</code></td>
                                        </tr>
                                        <tr>
                                            <td>CodeLlama</td>
                                            <td>7B, 13B, 34B</td>
                                            <td>Code generation</td>
                                            <td>8GB RAM</td>
                                            <td><code>ollama pull codellama</code></td>
                                        </tr>
                                        <tr>
                                            <td>Vicuna</td>
                                            <td>7B, 13B, 33B</td>
                                            <td>Instruction-following</td>
                                            <td>8GB RAM</td>
                                            <td><code>ollama pull vicuna</code></td>
                                        </tr>
                                        <tr>
                                            <td>Orca</td>
                                            <td>3B, 7B, 13B</td>
                                            <td>Reasoning tasks</td>
                                            <td>6GB RAM</td>
                                            <td><code>ollama pull orca</code></td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                            
                            <h3>Creating Custom Models</h3>
                            <p>
                                You can create custom models with specific parameters and libraries using a Modelfile:
                            </p>
                            
                            <div class="code-block">
                                <pre><code class="language-plaintext">FROM llama2
PARAMETER temperature 0.8
PARAMETER top_p 0.9
SYSTEM You are a helpful research assistant. You provide accurate, scientific information.

# Import libraries for extended functionality
LIBRARY search
LIBRARY calculator</code></pre>
                            </div>
                            
                            <p>Create your custom model with the following command:</p>
                            
                            <div class="code-block">
                                <pre><code class="language-bash">ollama create research-assistant -f ./Modelfile</code></pre>
                            </div>
                        </section>
                        
                        <div class="docs-navigation">
                            <a href="#introduction" class="docs-prev-link"><i class="fas fa-arrow-left"></i> Previous: Introduction</a>
                            <a href="#api-reference" class="docs-next-link">Next: API Reference <i class="fas fa-arrow-right"></i></a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>
    
    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="footer-content">
                <div class="footer-logo">
                    <img src="../../assets/images/llm-icon.svg" alt="Ollama Ecosystem Logo">
                    <div>
                        <h2>Ollama Ecosystem</h2>
                        <span>Sovereign AI Solutions</span>
                    </div>
                </div>
                <div class="footer-links">
                    <div class="footer-links-column">
                        <h3>Product</h3>
                        <a href="../../index.html">Home</a>
                        <a href="../docs/index.html">Documentation</a>
                        <a href="../downloads/index.html">Downloads</a>
                        <a href="../tutorials/index.html">Tutorials</a>
                    </div>
                    <div class="footer-links-column">
                        <h3>Company</h3>
                        <a href="../about/index.html">About Us</a>
                        <a href="../contact/index.html">Contact</a>
                        <a href="../careers/index.html">Careers</a>
                        <a href="../best-practices/index.html">Best Practices</a>
                    </div>
                    <div class="footer-links-column">
                        <h3>Resources</h3>
                        <a href="../reports/index.html">Reports</a>
                        <a href="../blog/index.html">Blog</a>
                        <a href="../community/index.html">Community</a>
                        <a href="../support/index.html">Support</a>
                    </div>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2024 Ollama Ecosystem. All rights reserved.</p>
                <div class="footer-social">
                    <a href="#"><i class="fab fa-github"></i></a>
                    <a href="#"><i class="fab fa-twitter"></i></a>
                    <a href="#"><i class="fab fa-discord"></i></a>
                    <a href="#"><i class="fab fa-linkedin"></i></a>
                </div>
            </div>
        </div>
    </footer>

    <!-- JavaScript -->
    <script src="../../assets/js/main.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/components/prism-json.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/components/prism-powershell.min.js"></script>
    <script>
        // Tab functionality
        document.addEventListener('DOMContentLoaded', function() {
            const tabBtns = document.querySelectorAll('.tab-btn');
            
            tabBtns.forEach(btn => {
                btn.addEventListener('click', function() {
                    // Remove active class from all buttons and panes
                    tabBtns.forEach(b => b.classList.remove('active'));
                    document.querySelectorAll('.tab-pane').forEach(pane => pane.classList.remove('active'));
                    
                    // Add active class to clicked button and corresponding pane
                    this.classList.add('active');
                    document.getElementById(this.getAttribute('data-target')).classList.add('active');
                });
            });
            
            // Smooth scrolling for in-page navigation
            document.querySelectorAll('a[href^="#"]').forEach(anchor => {
                anchor.addEventListener('click', function(e) {
                    e.preventDefault();
                    
                    const targetId = this.getAttribute('href');
                    const targetElement = document.querySelector(targetId);
                    
                    if (targetElement) {
                        window.scrollTo({
                            top: targetElement.offsetTop - 100,
                            behavior: 'smooth'
                        });
                        
                        // Update active state in sidebar
                        document.querySelectorAll('.docs-nav a').forEach(link => {
                            link.classList.remove('active');
                        });
                        document.querySelector(`.docs-nav a[href="${targetId}"]`).classList.add('active');
                    }
                });
            });
            
            // Handle scroll to update active sidebar link
            window.addEventListener('scroll', function() {
                const sections = document.querySelectorAll('.docs-section');
                let currentSection = '';
                
                sections.forEach(section => {
                    const sectionTop = section.offsetTop - 120;
                    const sectionHeight = section.offsetHeight;
                    if (window.scrollY >= sectionTop && window.scrollY < sectionTop + sectionHeight) {
                        currentSection = '#' + section.getAttribute('id');
                    }
                });
                
                if (currentSection) {
                    document.querySelectorAll('.docs-nav a').forEach(link => {
                        link.classList.remove('active');
                    });
                    
                    const activeLink = document.querySelector(`.docs-nav a[href="${currentSection}"]`);
                    if (activeLink) {
                        activeLink.classList.add('active');
                    }
                }
            });
        });
    </script>
</body>
</html> 